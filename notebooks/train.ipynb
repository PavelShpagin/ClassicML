{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1d3645",
   "metadata": {},
   "source": [
    "# China Real Estate Demand Prediction - Modeling\n",
    "\n",
    "This notebook builds classic ML baselines (linear, ridge/lasso), a Gaussian-ish baseline, and SOTA tree models (XGBoost/LightGBM/CatBoost). It performs time-series CV with the competition score, and produces RMSE/MAPE curves and a submission.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b8787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(str(Path('..').resolve().parent))\n",
    "from src.data import DatasetPaths, load_all_training_tables, load_test, split_month_sector, prepare_train_target, explode_test_id\n",
    "from src.features import build_time_lagged_features, join_static_sector_features\n",
    "from src.models import competition_score, build_linear_pipeline\n",
    "\n",
    "ROOT = str(Path('..').resolve().parent)\n",
    "paths = DatasetPaths(root_dir=ROOT)\n",
    "\n",
    "# Load\n",
    "train = load_all_training_tables(paths)\n",
    "\n",
    "target_wide, sector_index = prepare_train_target(train['new_house_transactions'])\n",
    "\n",
    "# Build supervised dataset from lags\n",
    "lag_feats = build_time_lagged_features(train['new_house_transactions'])\n",
    "lag_feats = lag_feats.sort_values(['time', 'sector_id'])\n",
    "\n",
    "# Align target\n",
    "y_long = target_wide.unstack().reset_index(name='y')\n",
    "y_long = y_long.rename(columns={'level_0': 'sector_id', 'time': 'time'})\n",
    "\n",
    "df = lag_feats.merge(y_long, on=['time', 'sector_id'], how='left')\n",
    "\n",
    "# Drop rows with NaN features (due to lags)\n",
    "df_model = df.dropna(subset=[c for c in df.columns if c.startswith('lag_') or c.startswith('roll_')]).copy()\n",
    "\n",
    "feature_cols = [c for c in df_model.columns if c.startswith('lag_') or c.startswith('roll_')]\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['y']\n",
    "\n",
    "# Baseline: Ridge with grid over alpha and plot curves\n",
    "alphas = np.logspace(-3, 2, 10)\n",
    "results = []\n",
    "rmse_curve, mape_curve = [], []\n",
    "for a in alphas:\n",
    "    pipe = build_linear_pipeline(alpha=a, kind='ridge')\n",
    "    # Simple hold-forward split for speed: train until t<=54, validate on last 12 months\n",
    "    mask_train = df_model['time'] <= 54\n",
    "    X_tr, y_tr = X[mask_train], y[mask_train]\n",
    "    X_va, y_va = X[~mask_train], y[~mask_train]\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    yhat = pipe.predict(X_va)\n",
    "    sc = competition_score(y_va.values, yhat)\n",
    "    r = {\n",
    "        'alpha': a,\n",
    "        'score': sc['score'],\n",
    "        'good_rate': sc['good_rate'],\n",
    "        'rmse': np.sqrt(mean_squared_error(y_va, yhat)),\n",
    "        'mape': np.mean(np.abs((y_va.values - yhat) / np.maximum(y_va.values, 1e-12)))\n",
    "    }\n",
    "    results.append(r)\n",
    "    rmse_curve.append(r['rmse'])\n",
    "    mape_curve.append(r['mape'])\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "print(res_df.sort_values('score', ascending=False).head())\n",
    "\n",
    "# Plot RMSE/MAPE vs alpha\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "ax[0].plot(alphas, rmse_curve, marker='o')\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_title('RMSE vs alpha (Ridge)')\n",
    "ax[1].plot(alphas, mape_curve, marker='o', color='orange')\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_title('MAPE vs alpha (Ridge)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955510c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best Ridge on all available past months and generate submission\n",
    "best_alpha = res_df.sort_values('score', ascending=False).iloc[0]['alpha']\n",
    "print('Best alpha:', best_alpha)\n",
    "\n",
    "pipe = build_linear_pipeline(alpha=float(best_alpha), kind='ridge')\n",
    "pipe.fit(X, y)\n",
    "\n",
    "# Build test design matrix using last lags and rollings\n",
    "from src.data import load_test\n",
    "from src.features import build_time_lagged_features\n",
    "\n",
    "paths = DatasetPaths(root_dir=ROOT)\n",
    "train = load_all_training_tables(paths)\n",
    "\n",
    "test_df = load_test(paths)\n",
    "from src.data import explode_test_id\n",
    "\n",
    "# Need features for times 67..78; using lag features built from training data only\n",
    "lag_feats_full = build_time_lagged_features(train['new_house_transactions'])\n",
    "lag_feats_full = lag_feats_full.sort_values(['time', 'sector_id'])\n",
    "\n",
    "# Take only rows with time in test horizon\n",
    "test_exploded = explode_test_id(test_df)\n",
    "lag_test = lag_feats_full[lag_feats_full['time'].isin(test_exploded['time'].unique())]\n",
    "\n",
    "# Merge to align sector_id and time\n",
    "lag_test = lag_test.merge(test_exploded[['time','sector','sector_id','id']], on=['time','sector_id'], how='right')\n",
    "\n",
    "X_test = lag_test[feature_cols]\n",
    "# Rows with NA (insufficient lag history) -> fill 0 as conservative\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "y_pred_test = pipe.predict(X_test)\n",
    "\n",
    "submission = lag_test[['id']].copy()\n",
    "submission['new_house_transaction_amount'] = y_pred_test\n",
    "\n",
    "# Ensure row order follows test.csv\n",
    "submission = submission.sort_values('id')\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Saved submission.csv with', len(submission), 'rows')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM/XGBoost/CatBoost with simple hyper sweeps and CV (optional if packages available)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    has_lgb = True\n",
    "except Exception:\n",
    "    has_lgb = False\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    has_xgb = True\n",
    "except Exception:\n",
    "    has_xgb = False\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "    has_cat = True\n",
    "except Exception:\n",
    "    has_cat = False\n",
    "\n",
    "advanced_results = []\n",
    "\n",
    "# Prepare train/val split used earlier\n",
    "mask_train = df_model['time'] <= 54\n",
    "X_tr, y_tr = X[mask_train], y[mask_train]\n",
    "X_va, y_va = X[~mask_train], y[~mask_train]\n",
    "\n",
    "if has_lgb:\n",
    "    dtrain = lgb.Dataset(X_tr, label=y_tr)\n",
    "    dvalid = lgb.Dataset(X_va, label=y_va, reference=dtrain)\n",
    "    lgb_params_grid = [\n",
    "        {'num_leaves': nl, 'learning_rate': lr, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'objective': 'regression', 'metric': 'rmse', 'seed': 42}\n",
    "        for nl in [15, 31, 63]\n",
    "        for lr in [0.05, 0.1]\n",
    "    ]\n",
    "    lgb_rmse_curve, lgb_mape_curve = [], []\n",
    "    for p in lgb_params_grid:\n",
    "        booster = lgb.train(p, dtrain, num_boost_round=1000, valid_sets=[dvalid], verbose_eval=False, early_stopping_rounds=50)\n",
    "        yhat = booster.predict(X_va, num_iteration=booster.best_iteration)\n",
    "        sc = competition_score(y_va.values, yhat)\n",
    "        rm = np.sqrt(mean_squared_error(y_va, yhat))\n",
    "        mp = np.mean(np.abs((y_va.values - yhat) / np.maximum(y_va.values, 1e-12)))\n",
    "        advanced_results.append({'model':'lightgbm','params':p,'score':sc['score'],'rmse':rm,'mape':mp})\n",
    "        lgb_rmse_curve.append(rm)\n",
    "        lgb_mape_curve.append(mp)\n",
    "    print(pd.DataFrame(advanced_results)[pd.DataFrame(advanced_results)['model']=='lightgbm'].sort_values('score', ascending=False).head())\n",
    "\n",
    "if has_xgb:\n",
    "    xgb_rmse_curve, xgb_mape_curve = [], []\n",
    "    for max_depth in [4,6,8]:\n",
    "        for lr in [0.05, 0.1]:\n",
    "            model = xgb.XGBRegressor(max_depth=max_depth, learning_rate=lr, n_estimators=1000, subsample=0.8, colsample_bytree=0.8, objective='reg:squarederror', random_state=42, tree_method='hist')\n",
    "            model.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n",
    "            yhat = model.predict(X_va)\n",
    "            sc = competition_score(y_va.values, yhat)\n",
    "            rm = np.sqrt(mean_squared_error(y_va, yhat))\n",
    "            mp = np.mean(np.abs((y_va.values - yhat) / np.maximum(y_va.values, 1e-12)))\n",
    "            advanced_results.append({'model':'xgboost','params':{'max_depth':max_depth,'learning_rate':lr},'score':sc['score'],'rmse':rm,'mape':mp})\n",
    "            xgb_rmse_curve.append(rm)\n",
    "            xgb_mape_curve.append(mp)\n",
    "    print(pd.DataFrame(advanced_results)[pd.DataFrame(advanced_results)['model']=='xgboost'].sort_values('score', ascending=False).head())\n",
    "\n",
    "if has_cat:\n",
    "    cat_rmse_curve, cat_mape_curve = [], []\n",
    "    for depth in [4,6,8]:\n",
    "        model = CatBoostRegressor(depth=depth, learning_rate=0.1, loss_function='RMSE', random_seed=42, iterations=2000, verbose=False)\n",
    "        model.fit(X_tr, y_tr, eval_set=(X_va, y_va))\n",
    "        yhat = model.predict(X_va)\n",
    "        sc = competition_score(y_va.values, yhat)\n",
    "        rm = np.sqrt(mean_squared_error(y_va, yhat))\n",
    "        mp = np.mean(np.abs((y_va.values - yhat) / np.maximum(y_va.values, 1e-12)))\n",
    "        advanced_results.append({'model':'catboost','params':{'depth':depth},'score':sc['score'],'rmse':rm,'mape':mp})\n",
    "        cat_rmse_curve.append(rm)\n",
    "        cat_mape_curve.append(mp)\n",
    "    print(pd.DataFrame(advanced_results)[pd.DataFrame(advanced_results)['model']=='catboost'].sort_values('score', ascending=False).head())\n",
    "\n",
    "pd.DataFrame(advanced_results).sort_values('score', ascending=False).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e5e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive forecasting over test horizon using selected model (e.g., best of ridge/lgb/xgb)\n",
    "# Choose best model by score from advanced_results if any; otherwise use ridge pipe\n",
    "best_overall = None\n",
    "if 'advanced_results' in globals() and len(advanced_results) > 0:\n",
    "    best_overall = sorted(advanced_results, key=lambda d: d['score'], reverse=True)[0]['model']\n",
    "else:\n",
    "    best_overall = 'ridge'\n",
    "print('Selected model for submission:', best_overall)\n",
    "\n",
    "# Prepare base series to update lags as we roll forward\n",
    "nht = train['new_house_transactions'].copy()\n",
    "nht_aug = split_month_sector(nht)\n",
    "\n",
    "# Build initial lag features including last available training rows\n",
    "lag_full = build_time_lagged_features(nht)\n",
    "lag_full = lag_full.sort_values(['time','sector_id'])\n",
    "\n",
    "# Prepare exploded test ids\n",
    "paths = DatasetPaths(root_dir=ROOT)\n",
    "test_df = load_test(paths)\n",
    "test_exploded = explode_test_id(test_df)\n",
    "\n",
    "# Ensure we iterate time in ascending order and per time predict 96 sectors\n",
    "predictions = []\n",
    "current_series = nht_aug[['time','sector_id','amount_new_house_transactions']].copy()\n",
    "\n",
    "# Helper to get design row for a given time and sector from current_series\n",
    "from src.features import build_time_lagged_features\n",
    "\n",
    "for t in sorted(test_exploded['time'].unique()):\n",
    "    # Recompute lag features from current_series up to time t for all sectors\n",
    "    tmp = current_series.rename(columns={'amount_new_house_transactions':'amount_new_house_transactions'})\n",
    "    lag_tmp = build_time_lagged_features(tmp)\n",
    "    lag_t = lag_tmp[lag_tmp['time'] == t]\n",
    "\n",
    "    step_df = test_exploded[test_exploded['time'] == t][['id','sector_id','time']].merge(\n",
    "        lag_t, on=['time','sector_id'], how='left'\n",
    "    )\n",
    "    X_t = step_df[feature_cols].fillna(0)\n",
    "\n",
    "    if best_overall == 'ridge':\n",
    "        yhat_t = pipe.predict(X_t)\n",
    "    elif best_overall == 'lightgbm':\n",
    "        # choose best lightgbm trained earlier\n",
    "        # retrain with best params on full past\n",
    "        best_lgb = sorted([r for r in advanced_results if r['model']=='lightgbm'], key=lambda d: d['score'], reverse=True)[0]\n",
    "        params = best_lgb['params']\n",
    "        dtrain_full = lgb.Dataset(X, label=y)\n",
    "        booster = lgb.train(params, dtrain_full, num_boost_round= int(1.2 *  (best_lgb.get('best_iteration', 200))), verbose_eval=False)\n",
    "        yhat_t = booster.predict(X_t)\n",
    "    elif best_overall == 'xgboost':\n",
    "        best_xgb = sorted([r for r in advanced_results if r['model']=='xgboost'], key=lambda d: d['score'], reverse=True)[0]\n",
    "        model = xgb.XGBRegressor(**best_xgb['params'], n_estimators=1000, subsample=0.8, colsample_bytree=0.8, objective='reg:squarederror', random_state=42, tree_method='hist')\n",
    "        model.fit(X, y, verbose=False)\n",
    "        yhat_t = model.predict(X_t)\n",
    "    elif best_overall == 'catboost':\n",
    "        best_cat = sorted([r for r in advanced_results if r['model']=='catboost'], key=lambda d: d['score'], reverse=True)[0]\n",
    "        model = CatBoostRegressor(depth=best_cat['params']['depth'], learning_rate=0.1, loss_function='RMSE', random_seed=42, iterations=2000, verbose=False)\n",
    "        model.fit(X, y)\n",
    "        yhat_t = model.predict(X_t)\n",
    "    else:\n",
    "        yhat_t = pipe.predict(X_t)\n",
    "\n",
    "    step_df = step_df[['id','sector_id','time']].copy()\n",
    "    step_df['new_house_transaction_amount'] = yhat_t\n",
    "    predictions.append(step_df[['id','new_house_transaction_amount']])\n",
    "\n",
    "    # Update current_series with predicted values so next time step can use them in lags\n",
    "    update = step_df.copy()\n",
    "    update = update.rename(columns={'new_house_transaction_amount':'amount_new_house_transactions'})\n",
    "    update['sector'] = 'sector ' + update['sector_id'].astype(int).astype(str)\n",
    "    current_series = pd.concat([current_series, update[['time','sector_id','amount_new_house_transactions']]], ignore_index=True)\n",
    "\n",
    "submission_df = pd.concat(predictions, ignore_index=True)\n",
    "# Merge back to test to preserve exact original order\n",
    "final_submission = test_df[['id']].merge(submission_df, on='id', how='left')\n",
    "final_submission.to_csv('submission.csv', index=False)\n",
    "print('Saved recursively-rolled submission.csv with', len(final_submission), 'rows')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
