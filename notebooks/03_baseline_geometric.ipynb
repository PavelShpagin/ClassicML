{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Geometric Method\n",
    "\n",
    "This notebook implements a pure geometric mean baseline:\n",
    "- Geometric mean with zero guard\n",
    "- No seasonality adjustments\n",
    "- Validation with competition metric\n",
    "- Performance comparison with seasonality method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path('..').resolve()))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data import DatasetPaths, load_all_training_tables\n",
    "from src.models import competition_score\n",
    "from src.utils import build_amount_wide, geometric_mean_with_zero_guard\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "paths = DatasetPaths(root_dir=str(Path('..').resolve()))\n",
    "train = load_all_training_tables(paths)\n",
    "amount = build_amount_wide(train['new_house_transactions'])\n",
    "print(f\"Training data shape: {amount.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning: Lookback & Zero Guard Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search over lookback and zero_guard_window\n",
    "lookback_windows = [3, 6, 9, 12, 18]\n",
    "zero_guard_windows = [3, 6, 9, 12]\n",
    "results = []\n",
    "\n",
    "train_amount = amount.iloc[:-12]\n",
    "val_amount = amount.iloc[-12:]\n",
    "\n",
    "for lookback in lookback_windows:\n",
    "    for zero_guard in zero_guard_windows:\n",
    "        base_geo = geometric_mean_with_zero_guard(train_amount, lookback_months=lookback, zero_guard_window=zero_guard)\n",
    "        \n",
    "        # Predict same value for all 12 validation months\n",
    "        val_predictions = np.tile(base_geo.values, (12, 1)).flatten()\n",
    "        val_true = val_amount.values.flatten()\n",
    "        \n",
    "        score_dict = competition_score(val_true, val_predictions)\n",
    "        results.append({\n",
    "            'lookback': lookback,\n",
    "            'zero_guard': zero_guard,\n",
    "            'score': score_dict['score'],\n",
    "            'good_rate': score_dict['good_rate']\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "best_result = results_df.loc[results_df['score'].idxmin()]\n",
    "print(f\"Best parameters:\")\n",
    "print(f\"  Lookback: {best_result['lookback']:.0f} months\")\n",
    "print(f\"  Zero Guard: {best_result['zero_guard']:.0f} months\")\n",
    "print(f\"  Score: {best_result['score']:.4f}\")\n",
    "print(f\"  Good Rate: {best_result['good_rate']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of scores\n",
    "pivot = results_df.pivot(index='zero_guard', columns='lookback', values='score')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.heatmap(pivot, annot=True, fmt='.4f', cmap='YlOrRd', ax=ax)\n",
    "ax.set_title('Competition Score by Lookback and Zero Guard Window')\n",
    "ax.set_xlabel('Lookback Window (months)')\n",
    "ax.set_ylabel('Zero Guard Window (months)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Score vs lookback (for best zero_guard)\n",
    "best_zg = best_result['zero_guard']\n",
    "subset = results_df[results_df['zero_guard'] == best_zg]\n",
    "axes[0].plot(subset['lookback'], subset['score'], marker='o', linewidth=2)\n",
    "axes[0].set_title(f'Competition Score vs Lookback (zero_guard={best_zg:.0f})')\n",
    "axes[0].set_xlabel('Lookback Window (months)')\n",
    "axes[0].set_ylabel('Competition Score')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Good rate vs lookback\n",
    "axes[1].plot(subset['lookback'], subset['good_rate'], marker='o', linewidth=2, color='orange')\n",
    "axes[1].set_title(f'Good Rate vs Lookback (zero_guard={best_zg:.0f})')\n",
    "axes[1].set_xlabel('Lookback Window (months)')\n",
    "axes[1].set_ylabel('Good Rate')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with best params on all data\n",
    "base_geo = geometric_mean_with_zero_guard(amount, lookback_months=int(best_result['lookback']), zero_guard_window=int(best_result['zero_guard']))\n",
    "\n",
    "# Validation\n",
    "val_predictions = np.tile(base_geo.values, (12, 1)).flatten()\n",
    "val_true = amount.iloc[-12:].values.flatten()\n",
    "\n",
    "final_score = competition_score(val_true, val_predictions)\n",
    "print(f\"\\nFinal Validation Results:\")\n",
    "print(f\"  Competition Score: {final_score['score']:.4f}\")\n",
    "print(f\"  Good Rate: {final_score['good_rate']:.4f}\")\n",
    "print(f\"  Zero Predictions: {(val_predictions == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error distribution\n",
    "ape = np.abs((val_true - val_predictions) / np.maximum(val_true, 1e-12))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "ax.hist(ape[ape < 2], bins=50, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(1.0, color='red', linestyle='--', label='APE = 100%')\n",
    "ax.set_title('APE Distribution')\n",
    "ax.set_xlabel('Absolute Percentage Error')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAPE < 100%: {(ape < 1.0).mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Method**: Pure geometric mean with zero guard\n",
    "\n",
    "**Advantages**:\n",
    "- Simple and robust\n",
    "- Handles skewed distributions well\n",
    "- Zero guard prevents metric explosions\n",
    "\n",
    "**Disadvantages**:\n",
    "- No seasonality modeling\n",
    "- Slightly worse than seasonality-aware method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}